{"cells":[{"cell_type":"markdown","metadata":{"id":"npR7SDkJSL7q"},"source":["# Face Recognition\n","- Face recognition with LBPH and OpenCV\n","- Face recognition with Dlib, CNN and distance calculation\n"]},{"cell_type":"markdown","metadata":{"id":"52F1UFjnSL7t"},"source":["### LBPH (LOCAL BINARY PATTERNS HISTOGRAMS)\n","LBPH(Local Binary Patterns Histograms)은 이미지에서 지역적인 이진 패턴을 추출하여 각 픽셀의 주변 텍스처와 패턴을 특징화하는 알고리즘이다.\n","중앙값 픽셀을 기준으로 크거나 같으면 1 작으면 0으로 표현하고 중앙값을 제외 후 1 또는 0을 이어주면 이진수가 나타나는데 이것이 해당 픽셀이 나타내고 있는 특징으로 볼 수 있다. 이러한 이진수는 밝기를 조절할때 강력하고 각각의 이진수 패턴을 히스토그램으로 통계적으로 표현할 수 있다. 이런 히스토그램을 가지고 있는 한 픽셀을 학습한 데이터의 히스토그램과 비교하여 얼굴을 인식할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"iNW_NuKNrrna"},"source":["### Loading the dataset\n","- 앞으로 사용할 데이터셋의 출처 = Yale faces database\n","  - url: http://vision.ucsd.edu/content/yale-face-database\n"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2645,"status":"ok","timestamp":1706527168231,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"G0iFCsmssDrD","outputId":"9872c207-2ae6-4611-a178-fd283b65f5ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#PIL(Pillow) 이미지 처리 라이브러리(gif이미지, 간단한 이미지 작업)\n","from PIL import Image\n","import cv2 # 이미지 처리 라이브러리(컴퓨터 비전 처리)\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"kmKOfIyNtKxy","executionInfo":{"status":"ok","timestamp":1706527168231,"user_tz":-540,"elapsed":6,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["# zip 압축 파일을 추출할 라이브러리\n","import zipfile\n","path = '/content/drive/MyDrive/Colab Notebooks/Project/Computer Vision/src/Datasets/yalefaces.zip'\n","# mode는 읽기, 쓰기, 읽고쓰기 중 어떤 작업을 할지 정하는것이다. r을 read이다.\n","zip_object =zipfile.ZipFile(file = path, mode = 'r')\n","# 현재위치에서 파일을 생성해라\n","zip_object.extractall('./')\n","zip_object.close()"]},{"cell_type":"markdown","metadata":{"id":"WLWuYlyjvNTW"},"source":["### Pre-processing the images( 데이터 전처리 )\n","- 준비한 데이터셋을 얼굴인식 알고리즘에서 사용할 수 있도록 알맞은 형태로 전처리하는 과정\n"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1706527168231,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"vSUwumeVvfYC","outputId":"57deffc3-1235-4800-9aa7-8402db544cdf"},"outputs":[{"output_type":"stream","name":"stdout","text":["['subject11.rightlight.gif', 'subject12.sad.gif', 'subject07.rightlight.gif', 'subject14.glasses.gif', 'subject15.glasses.gif', 'subject05.rightlight.gif', 'subject04.happy.gif', 'subject11.centerlight.gif', 'subject15.normal.gif', 'subject01.surprised.gif', 'subject02.normal.gif', 'subject13.glasses.gif', 'subject05.glasses.gif', 'subject02.rightlight.gif', 'subject11.leftlight.gif', 'subject11.noglasses.gif', 'subject02.wink.gif', 'subject06.sleepy.gif', 'subject08.sad.gif', 'subject03.sad.gif', 'subject14.rightlight.gif', 'subject08.centerlight.gif', 'subject01.leftlight.gif', 'subject07.glasses.gif', 'subject14.centerlight.gif', 'subject05.normal.gif', 'subject06.rightlight.gif', 'subject12.centerlight.gif', 'subject05.leftlight.gif', 'subject14.wink.gif', 'subject07.sleepy.gif', 'subject14.noglasses.gif', 'subject07.centerlight.gif', 'subject04.sleepy.gif', 'subject06.noglasses.gif', 'subject13.leftlight.gif', 'subject14.sleepy.gif', 'subject03.centerlight.gif', 'subject12.surprised.gif', 'subject15.surprised.gif', 'subject05.noglasses.gif', 'subject05.happy.gif', 'subject13.normal.gif', 'subject13.noglasses.gif', 'subject03.normal.gif', 'subject01.wink.gif', 'subject10.sleepy.gif', 'subject14.happy.gif', 'subject09.wink.gif', 'subject08.wink.gif', 'subject07.sad.gif', 'subject15.noglasses.gif', 'subject08.glasses.gif', 'subject15.leftlight.gif', 'subject14.leftlight.gif', 'subject10.rightlight.gif', 'subject07.noglasses.gif', 'subject15.centerlight.gif', 'subject06.sad.gif', 'subject02.surprised.gif', 'subject04.normal.gif', 'subject03.sleepy.gif', 'subject06.normal.gif', 'subject04.sad.gif', 'subject08.sleepy.gif', 'subject11.sad.gif', 'subject11.wink.gif', 'subject12.noglasses.gif', 'subject10.happy.gif', 'subject10.wink.gif', 'subject08.noglasses.gif', 'subject05.centerlight.gif', 'subject08.leftlight.gif', 'subject06.glasses.gif', 'subject12.glasses.gif', 'subject02.happy.gif', 'subject15.sleepy.gif', 'subject08.surprised.gif', 'subject02.noglasses.gif', 'subject15.wink.gif', 'subject15.happy.gif', 'subject12.wink.gif', 'subject03.wink.gif', 'subject13.surprised.gif', 'subject01.glasses.gif', 'subject06.centerlight.gif', 'subject14.surprised.gif', 'subject13.rightlight.gif', 'subject02.glasses.gif', 'subject09.noglasses.gif', 'subject08.happy.gif', 'subject06.wink.gif', 'subject01.normal.gif', 'subject03.rightlight.gif', 'subject13.happy.gif', 'subject10.leftlight.gif', 'subject13.wink.gif', 'subject09.happy.gif', 'subject11.sleepy.gif', 'subject02.sad.gif', 'subject01.sad.gif', 'subject03.noglasses.gif', 'subject03.happy.gif', 'subject12.happy.gif', 'subject01.sleepy.gif', 'subject07.surprised.gif', 'subject04.centerlight.gif', 'subject12.leftlight.gif', 'subject01.rightlight.gif', 'subject12.sleepy.gif', 'subject10.surprised.gif', 'subject01.noglasses.gif', 'subject04.wink.gif', 'subject04.rightlight.gif', 'subject09.normal.gif', 'subject07.wink.gif', 'subject07.normal.gif', 'subject09.centerlight.gif', 'subject11.surprised.gif', 'subject10.noglasses.gif', 'subject04.glasses.gif', 'subject10.normal.gif', 'subject09.leftlight.gif', 'subject11.normal.gif', 'subject13.centerlight.gif', 'subject09.glasses.gif', 'subject03.surprised.gif', 'subject10.glasses.gif', 'subject09.sleepy.gif', 'subject05.wink.gif', 'subject04.noglasses.gif', 'subject06.surprised.gif', 'subject02.sleepy.gif', 'subject05.sad.gif', 'subject09.surprised.gif']\n"]}],"source":["import os\n","# os.listdir()는 매개변수안에 있는 파일들을 다 보여준다\n","print(os.listdir('/content/yalefaces/train'))"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"kM_QUHnm31AR","executionInfo":{"status":"ok","timestamp":1706527168231,"user_tz":-540,"elapsed":4,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["# 이미지를 가져온 다음 본 알고리즘에 맞는 형식으로 전송하는 함수\n","def get_image_data():\n","  paths=[os.path.join('/content/yalefaces/train',f) for f in os.listdir('/content/yalefaces/train')]\n","  print(paths)\n","  # 불러온 이미지 저장\n","  faces = []\n","  # 이미지의 객체 대상 저장\n","  ids = []\n","  for path in paths:\n","    # gif이미지를 가져와서 numpy로 변환, convert의 L mode는 단일 채널 이미지로 흑백 이미지이다.\n","    image = Image.open(path).convert('L')\n","    # PIL의 image 객체로 반환된 데이터를 opencv로 사용할려면 numpy로 변환해야된다.(unit8은 각 픽셀이 정수형 값을 갖는 이미지이다.)\n","    image_np = np. array(image, 'uint8')\n","    # 각각의 이미지의 객체 번호를 받아오는 작업\n","    id = int(os.path.split(path)[1].split('.')[0].replace('subject',''))\n","    ids.append(id)\n","    faces.append(image_np)\n","  return np.array(ids), faces\n"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706527168231,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"5sHf_f5j_WI7","outputId":"ad157d21-ef34-4378-95c0-304425853c15"},"outputs":[{"output_type":"stream","name":"stdout","text":["['/content/yalefaces/train/subject11.rightlight.gif', '/content/yalefaces/train/subject12.sad.gif', '/content/yalefaces/train/subject07.rightlight.gif', '/content/yalefaces/train/subject14.glasses.gif', '/content/yalefaces/train/subject15.glasses.gif', '/content/yalefaces/train/subject05.rightlight.gif', '/content/yalefaces/train/subject04.happy.gif', '/content/yalefaces/train/subject11.centerlight.gif', '/content/yalefaces/train/subject15.normal.gif', '/content/yalefaces/train/subject01.surprised.gif', '/content/yalefaces/train/subject02.normal.gif', '/content/yalefaces/train/subject13.glasses.gif', '/content/yalefaces/train/subject05.glasses.gif', '/content/yalefaces/train/subject02.rightlight.gif', '/content/yalefaces/train/subject11.leftlight.gif', '/content/yalefaces/train/subject11.noglasses.gif', '/content/yalefaces/train/subject02.wink.gif', '/content/yalefaces/train/subject06.sleepy.gif', '/content/yalefaces/train/subject08.sad.gif', '/content/yalefaces/train/subject03.sad.gif', '/content/yalefaces/train/subject14.rightlight.gif', '/content/yalefaces/train/subject08.centerlight.gif', '/content/yalefaces/train/subject01.leftlight.gif', '/content/yalefaces/train/subject07.glasses.gif', '/content/yalefaces/train/subject14.centerlight.gif', '/content/yalefaces/train/subject05.normal.gif', '/content/yalefaces/train/subject06.rightlight.gif', '/content/yalefaces/train/subject12.centerlight.gif', '/content/yalefaces/train/subject05.leftlight.gif', '/content/yalefaces/train/subject14.wink.gif', '/content/yalefaces/train/subject07.sleepy.gif', '/content/yalefaces/train/subject14.noglasses.gif', '/content/yalefaces/train/subject07.centerlight.gif', '/content/yalefaces/train/subject04.sleepy.gif', '/content/yalefaces/train/subject06.noglasses.gif', '/content/yalefaces/train/subject13.leftlight.gif', '/content/yalefaces/train/subject14.sleepy.gif', '/content/yalefaces/train/subject03.centerlight.gif', '/content/yalefaces/train/subject12.surprised.gif', '/content/yalefaces/train/subject15.surprised.gif', '/content/yalefaces/train/subject05.noglasses.gif', '/content/yalefaces/train/subject05.happy.gif', '/content/yalefaces/train/subject13.normal.gif', '/content/yalefaces/train/subject13.noglasses.gif', '/content/yalefaces/train/subject03.normal.gif', '/content/yalefaces/train/subject01.wink.gif', '/content/yalefaces/train/subject10.sleepy.gif', '/content/yalefaces/train/subject14.happy.gif', '/content/yalefaces/train/subject09.wink.gif', '/content/yalefaces/train/subject08.wink.gif', '/content/yalefaces/train/subject07.sad.gif', '/content/yalefaces/train/subject15.noglasses.gif', '/content/yalefaces/train/subject08.glasses.gif', '/content/yalefaces/train/subject15.leftlight.gif', '/content/yalefaces/train/subject14.leftlight.gif', '/content/yalefaces/train/subject10.rightlight.gif', '/content/yalefaces/train/subject07.noglasses.gif', '/content/yalefaces/train/subject15.centerlight.gif', '/content/yalefaces/train/subject06.sad.gif', '/content/yalefaces/train/subject02.surprised.gif', '/content/yalefaces/train/subject04.normal.gif', '/content/yalefaces/train/subject03.sleepy.gif', '/content/yalefaces/train/subject06.normal.gif', '/content/yalefaces/train/subject04.sad.gif', '/content/yalefaces/train/subject08.sleepy.gif', '/content/yalefaces/train/subject11.sad.gif', '/content/yalefaces/train/subject11.wink.gif', '/content/yalefaces/train/subject12.noglasses.gif', '/content/yalefaces/train/subject10.happy.gif', '/content/yalefaces/train/subject10.wink.gif', '/content/yalefaces/train/subject08.noglasses.gif', '/content/yalefaces/train/subject05.centerlight.gif', '/content/yalefaces/train/subject08.leftlight.gif', '/content/yalefaces/train/subject06.glasses.gif', '/content/yalefaces/train/subject12.glasses.gif', '/content/yalefaces/train/subject02.happy.gif', '/content/yalefaces/train/subject15.sleepy.gif', '/content/yalefaces/train/subject08.surprised.gif', '/content/yalefaces/train/subject02.noglasses.gif', '/content/yalefaces/train/subject15.wink.gif', '/content/yalefaces/train/subject15.happy.gif', '/content/yalefaces/train/subject12.wink.gif', '/content/yalefaces/train/subject03.wink.gif', '/content/yalefaces/train/subject13.surprised.gif', '/content/yalefaces/train/subject01.glasses.gif', '/content/yalefaces/train/subject06.centerlight.gif', '/content/yalefaces/train/subject14.surprised.gif', '/content/yalefaces/train/subject13.rightlight.gif', '/content/yalefaces/train/subject02.glasses.gif', '/content/yalefaces/train/subject09.noglasses.gif', '/content/yalefaces/train/subject08.happy.gif', '/content/yalefaces/train/subject06.wink.gif', '/content/yalefaces/train/subject01.normal.gif', '/content/yalefaces/train/subject03.rightlight.gif', '/content/yalefaces/train/subject13.happy.gif', '/content/yalefaces/train/subject10.leftlight.gif', '/content/yalefaces/train/subject13.wink.gif', '/content/yalefaces/train/subject09.happy.gif', '/content/yalefaces/train/subject11.sleepy.gif', '/content/yalefaces/train/subject02.sad.gif', '/content/yalefaces/train/subject01.sad.gif', '/content/yalefaces/train/subject03.noglasses.gif', '/content/yalefaces/train/subject03.happy.gif', '/content/yalefaces/train/subject12.happy.gif', '/content/yalefaces/train/subject01.sleepy.gif', '/content/yalefaces/train/subject07.surprised.gif', '/content/yalefaces/train/subject04.centerlight.gif', '/content/yalefaces/train/subject12.leftlight.gif', '/content/yalefaces/train/subject01.rightlight.gif', '/content/yalefaces/train/subject12.sleepy.gif', '/content/yalefaces/train/subject10.surprised.gif', '/content/yalefaces/train/subject01.noglasses.gif', '/content/yalefaces/train/subject04.wink.gif', '/content/yalefaces/train/subject04.rightlight.gif', '/content/yalefaces/train/subject09.normal.gif', '/content/yalefaces/train/subject07.wink.gif', '/content/yalefaces/train/subject07.normal.gif', '/content/yalefaces/train/subject09.centerlight.gif', '/content/yalefaces/train/subject11.surprised.gif', '/content/yalefaces/train/subject10.noglasses.gif', '/content/yalefaces/train/subject04.glasses.gif', '/content/yalefaces/train/subject10.normal.gif', '/content/yalefaces/train/subject09.leftlight.gif', '/content/yalefaces/train/subject11.normal.gif', '/content/yalefaces/train/subject13.centerlight.gif', '/content/yalefaces/train/subject09.glasses.gif', '/content/yalefaces/train/subject03.surprised.gif', '/content/yalefaces/train/subject10.glasses.gif', '/content/yalefaces/train/subject09.sleepy.gif', '/content/yalefaces/train/subject05.wink.gif', '/content/yalefaces/train/subject04.noglasses.gif', '/content/yalefaces/train/subject06.surprised.gif', '/content/yalefaces/train/subject02.sleepy.gif', '/content/yalefaces/train/subject05.sad.gif', '/content/yalefaces/train/subject09.surprised.gif']\n"]}],"source":["ids, faces = get_image_data()"]},{"cell_type":"markdown","metadata":{"id":"Gf_jKZhoA_Jj"},"source":["### Model Training( 모델 학습 )\n","- 전처리된 데이터를 활용하여 모델을 학습하는 과정"]},{"cell_type":"markdown","metadata":{"id":"GDi4ybuNCVDF"},"source":["### LBPH 매개변수(하이퍼파라미터)\n","- Radius: LBPH는 중앙값을 중심으로 일정 반지름의 길이만큼 원을 그려 이진수(이미지의 특징)를 파악한다. 그때 반지름의 길이를 설정할 수 있는 매개변수가 Radius이다\n","  - 기본값: 1\n","- Neighbors: Radius가 범위를 정하는거라면 Neighbors는 그 범위 안에서 사용하는 픽셀의 개수를 지정한다. 이 픽셀들의 이진 패턴을 사용하여 중앙 픽셀의 특징을 표현한다.\n","  - 기본값: 8\n","- grid_x, grid_y : 히스토그램을 가질수있는 구역(특징을 가진)을 gird_x * grid_y 크기로 나눌 수 있다.\n","  - 기본값 :8,8\n","- Threshold : 신뢰도를 뜻하고 이 값보다 낮은 신뢰도의 결과를 무시하는 매개변수이다. 클수록 확실한 특징만 알 수 있다.\n","  - 기본값 : 1.797..."]},{"cell_type":"code","execution_count":82,"metadata":{"id":"daXt9ep2PExh","executionInfo":{"status":"ok","timestamp":1706527267185,"user_tz":-540,"elapsed":44847,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["# threshold : 1.797...\n","# radius : 1\n","# neighbors : 8\n","# grid_x : 8\n","# grid_y : 8\n","lbph_classifier = cv2.face.LBPHFaceRecognizer_create(radius=4, neighbors=14, grid_x=9, grid_y=9)\n","lbph_classifier.train(faces, ids)\n","# 분류기를 저장할때 확장자는 기본적으로 yml이다.\n","lbph_classifier.write('lbph_classifier.yml')"]},{"cell_type":"markdown","metadata":{"id":"TKHyXpOLPs42"},"source":["### model inference ( 모델 사용 )\n","- 학습이 완료된 모델을 이용하여 실제 사용할 데이터의 클래스를 분류하는 과정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pk5rrDswRWah","executionInfo":{"status":"aborted","timestamp":1706527215357,"user_tz":-540,"elapsed":6,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["lbph_classifier = cv2.face.LBPHFaceRecognizer_create()\n","# 이전에 생성한 모델을 생성한 객체에 저장\n","lbph_classifier.read('lbph_classifier.yml')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1706527215357,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"0g4SXDJqS2GV"},"outputs":[],"source":["# test데이터도 모델에 사용할 수 있도록 전처리\n","test_image = '/content/yalefaces/test/subject05.sleepy.gif'\n","image = Image.open(test_image).convert('L')\n","image_np = np.array(image, 'uint8')\n","# 모델을 사용하여 분류(분류된 클레스, 신뢰도 - 높을수록좋음)\n","prediction = lbph_classifier.predict(image_np)\n","print(prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWJazSKbTMlg","executionInfo":{"status":"aborted","timestamp":1706527215357,"user_tz":-540,"elapsed":6,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["# 실제 정답 클래스 추출\n","expected_output = int(os.path.split(test_image)[1].split('.')[0].replace('subject',''))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1706527215357,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"BF0vq1-JTaWf"},"outputs":[],"source":["cv2.putText(image_np, 'Pred: '+ str(prediction[0]), (10,30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0)) # 예측\n","cv2.putText(image_np, 'Exp: '+ str(expected_output), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0)) # 정답\n","cv2_imshow(image_np)"]},{"cell_type":"markdown","metadata":{"id":"edeACkfnUmOf"},"source":["### Model Evaluation ( 모델 평가 )\n","- 학습이 완료된 모델을 이용하여 test 데이터를 사용하여 평가하는 작업\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EU1BzrzGVRAf","executionInfo":{"status":"aborted","timestamp":1706527215358,"user_tz":-540,"elapsed":7,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["paths=[os.path.join('/content/yalefaces/test',f) for f in os.listdir('/content/yalefaces/test')]\n","predictions =[]\n","expected_outuputs =[]\n","for path in paths:\n","  image = Image.open(path).convert('L')\n","  image_np = np. array(image, 'uint8')\n","  prediction = lbph_classifier.predict(image_np)\n","  expected_outupt = int(os.path.split(path)[1].split('.')[0].replace('subject',''))\n","  predictions.append(prediction[0])\n","  expected_outuputs.append(expected_outupt)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1706527215358,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"rhQfT_ZSWHIX"},"outputs":[],"source":["expected_outuputs = np.array(expected_outuputs)\n","predictions = np.array(predictions)\n","print(predictions)\n","print(expected_outuputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1706527215358,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"o9C2TIM3Womb"},"outputs":[],"source":["# sklearn은 대표적인 머신러닝 라이브러리이다.\n","from sklearn.metrics import accuracy_score\n","# 정확도 측정\n","accuracy_score(expected_outuputs, predictions)"]},{"cell_type":"markdown","metadata":{"id":"vox9zvPGZnd8"},"source":["##### 정확도 0.66666... 로 높지않다. 클래스가 전부 참이기도하고 오차행렬도 없어 정확도가 낮다."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1706527215358,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"vgzLoYQRaZgy"},"outputs":[],"source":["# confusion_matrix 생성\n","from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(expected_outuputs, predictions)\n","cm"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1706527215358,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"kSv62xhSat2s"},"outputs":[],"source":["# 좀 더 보기 좋게 시각화\n","import seaborn\n","# annot속성은 표안에 수치를 글자로 표시할지 선택하는 속성이다.\n","# 열을 실제 정답 클래스, 행은 예측 클래스\n","# 대각선은 맞힌 횟수, 열 밖에 있는 숫자는 틀린횟수\n","seaborn.heatmap(cm, annot = True);"]},{"cell_type":"markdown","metadata":{"id":"UTpRRXuebN7v"},"source":["### Dlib - Detecting facial points"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HttoD5nyHkqK","executionInfo":{"status":"aborted","timestamp":1706527215358,"user_tz":-540,"elapsed":6,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["import dlib\n","import cv2\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2p2vtbuHywJ","executionInfo":{"status":"aborted","timestamp":1706527215358,"user_tz":-540,"elapsed":6,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["face_detector= dlib.get_frontal_face_detector()\n","# 얼굴 랜드마크(landmarks)를 예측하기 위한 객체 (탐지된 얼굴안에서 작동)\n","points_detector = dlib.shape_predictor('/content/drive/MyDrive/Colab Notebooks/Project/Computer Vision/src/Weights/shape_predictor_68_face_landmarks.dat')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1706527215358,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"XmcMSaMwIvHF"},"outputs":[],"source":["image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Project/Computer Vision/src/Images/people2.jpg')\n","detections = face_detector(image,1)\n","for face in detections:\n","  # points_detector(원본이미지, 얼굴이 감지된 구역)\n","  points = points_detector(image,face)\n","  for point in points.parts():\n","    cv2.circle(image, (point.x,point.y),2,(0,255,0),1)\n","  # 감지된 얼굴안에서 68개의 포인트를 찾아낸다.\n","  # print(len(points.parts()), points.parts())\n","\n","  l, t,r,b = face.left(), face.top(), face.right(), face.bottom()\n","  cv2. rectangle(image, (l,t),(r,b),(0,255,255),3)\n","cv2_imshow(image)"]},{"cell_type":"markdown","metadata":{"id":"5lF0mw96I3kA"},"source":["### Detecting facial descriptors\n","- 각각의 얼굴 사진의 특징을 추출(CNN)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-fW2uPCO0tb","executionInfo":{"status":"aborted","timestamp":1706527215358,"user_tz":-540,"elapsed":6,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PV_BYtAJO1on","executionInfo":{"status":"aborted","timestamp":1706527215358,"user_tz":-540,"elapsed":5,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["# Resnet: https://arxiv.org/abs/1512.03385\n","face_detector= dlib.get_frontal_face_detector()\n","points_detector = dlib.shape_predictor('/content/drive/MyDrive/Colab Notebooks/Project/Computer Vision/src/Weights/shape_predictor_68_face_landmarks.dat')\n","# Resnet(CNN)을 이용한 얼굴 기술자 탐지 모델 생성\n","face_descriptor_extractor = dlib.face_recognition_model_v1('/content/drive/MyDrive/Colab Notebooks/Project/Computer Vision/src/Weights/dlib_face_recognition_resnet_model_v1.dat')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1706527215358,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"},"user_tz":-540},"id":"5VACroKaPaJF"},"outputs":[],"source":["index = {}\n","idx = 0\n","face_descriptors =None\n","paths=[os.path.join('/content/yalefaces/train',f) for f in os.listdir('/content/yalefaces/train')]\n","for path in paths:\n","  #CNN은 컬러 가능\n","  image = Image.open(path).convert('RGB')\n","  image_np = np.array(image, 'uint8')\n","  face_detection = face_detector(image_np,1)\n","  for face in face_detection:\n","    # 감지 안되는 얼굴 있음\n","    if not face.is_empty():\n","      l, t,r,b = face.left(), face.top(), face.right(), face.bottom()\n","      cv2.rectangle(image_np, (l,t),(r,b),(0,255,255),3)\n","      points = points_detector(image_np,face)\n","      for point in points.parts():\n","        cv2.circle(image_np, (point.x,point.y),2,(0,255,0),1)\n","\n","      # 특징 추출(CNN) ,128개의 특징으로 추출\n","      face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np,points)\n","      # 추출된 특징을 리스트 형식으로 변환 후 numpy로 변환\n","      face_descriptor = [f for f in face_descriptor]\n","      face_descriptor = np.asarray(face_descriptor, dtype = np.float64)\n","      # 1차원의 array이를 차원을 추가하여 두개의 차원으로 변경\n","      # 2차원으로 바꾸는 이유는 face_descripotrs로 각각의 face_descriptor을 넣어야되기때문이다.\n","      face_descriptor = face_descriptor[np.newaxis, : ]\n","      #print(face_descriptor.shape)\n","\n","      if face_descriptors is None:\n","        face_descriptors = face_descriptor\n","      else:\n","        face_descriptors = np.concatenate((face_descriptors, face_descriptor),axis=0)\n","\n","      index[idx] = path\n","      idx += 1\n","      #cv2_imshow(image_np)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AjcMxqogSjXU","executionInfo":{"status":"aborted","timestamp":1706527215358,"user_tz":-540,"elapsed":5,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"outputs":[],"source":["# numpy의 line alg 라이브러리에 norm() 함수를 사룡하면 서로다른 행렬의 특징값의 차이를 알수있다(작을수록 비슷한것)\n","np.linalg.norm(face_descriptors[131] - face_descriptors[131])\n","# numpy array자체를 넘겨버리면 모든 리스트의 값을 하나씩 적용하여 나온 결과를 리스트로 반환한다(1은 열, 0은 행)\n","np.linalg.norm(face_descriptors[131] - face_descriptors, axis = 1)"]},{"cell_type":"markdown","source":["### test데이터로 정확도 검증\n"],"metadata":{"id":"Gd6Q8TGfcopP"}},{"cell_type":"code","source":["threshold = 0.55 # 최소 신뢰도\n","\n","predictions =[]\n","expected_outputs =[]\n","\n","\n","paths=[os.path.join('/content/yalefaces/test',f) for f in os.listdir('/content/yalefaces/test')]\n","for path in paths:\n","  image = Image.open(path).convert('RGB')\n","  image_np = np.array(image, 'uint8')\n","  face_detection = face_detector(image_np,1)\n","  for face in face_detection: # 실습 이미지에선 하나만 나옴(얼굴이 하나이기 때문에)\n","    if not face.is_empty():\n","      points = points_detector(image_np,face)\n","      face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np,points)\n","      face_descriptor = [f for f in face_descriptor]\n","      face_descriptor = np.asarray(face_descriptor, dtype = np.float64)\n","      face_descriptor = face_descriptor[np.newaxis, : ]\n","\n","      # 이전에 생성했던 face_descriptors와 비교\n","      distances = np.linalg.norm(face_descriptor - face_descriptors, axis = 1)\n","      # 리스트로 반환된 값중 최소값을 가진 행 번호(index)를 가져옴\n","      min_index = np.argmin(distances)\n","      min_distance= distances[min_index]\n","      if min_distance <= threshold:\n","        name_pred = int(os.path.split(index[min_index])[1].split('.')[0].replace('subject',''))\n","      else:\n","        print(min_distance)\n","        name_pred = -1 # 'Not identified'\n","\n","    name_real = int(os.path.split(path)[1].split('.')[0].replace('subject',''))\n","\n","    predictions.append(name_pred)\n","    expected_outputs.append(name_real)\n","\n","    cv2.putText(image_np, 'Pred: '+ str(name_pred), (10,30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0)) # 예측\n","    cv2.putText(image_np, 'Exp: '+ str(name_real), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0)) # 정답\n","    cv2_imshow(image_np)\n"],"metadata":{"id":"jHH6HJcDwqe2","executionInfo":{"status":"aborted","timestamp":1706527215358,"user_tz":-540,"elapsed":5,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","accuracy_score(expected_outputs,predictions)"],"metadata":{"id":"5_0TP_ta1jY4","executionInfo":{"status":"aborted","timestamp":1706527215358,"user_tz":-540,"elapsed":5,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["연습 문제\n","\n","구글 드라이브의 Dataset 폴더에서 jones_gabriel.zip 파일을 다운로드한다.\n","새로운 데이터셋으로 얼굴 인식을 실습하라.\n","\n","- 이 데이터셋에는 학습용 이미지만 있기 때문에, 학습에 사용한 이미지로 평가도 해야 합니다.\n","\n","- 알고리즘을 학습시키고 매개 변수를 조정하세요."],"metadata":{"id":"2_QwNP_i3crK"}},{"cell_type":"code","source":[],"metadata":{"id":"xydgNYaL7Dkc","executionInfo":{"status":"aborted","timestamp":1706527215358,"user_tz":-540,"elapsed":5,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}