{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYPgAiyhd7irOpRue7JTzH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","# Convolutional Neural Network For Image Classification\n","\n","- CNN이란?\n","- Convolutional Neural Network For Image Classification\n","  - Approach 1 :\n","  - Approach 2 :"],"metadata":{"id":"il2e4F3-4WwX"}},{"cell_type":"markdown","source":["## CNN(Convolutional Neural Network)\n","- CNN은 ANN 이전에 Convolution 연산을 통해 이미지의 특징을 자동으로 찾는 기능을 추가한 것이다.\n","\n","- CNN의 구성은 합성곱 연산 -> 풀링 -> 평탄화 -> 밀집 신경망 으로 기본적으로 구성된다."],"metadata":{"id":"6ELbaDC44lez"}},{"cell_type":"markdown","source":["### Importing the Libraries & Loading the image\n","\n","- tensorflow로 학습을 하기위해선 training_set과 test_set으로 폴더를 나누어서 관리해야된다."],"metadata":{"id":"OTkdlsbotFiV"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import os\n","import zipfile\n","from google.colab.patches import cv_imshow\n","import tensorflow as tf\n","from tensorflow .keras.models import Sequential\n","# Convolution 연산을 위한 import\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n","# 이미지 전처리를 도와주는 객체( 테스트 데이터, 검증 데이터 분할, 이미지 늘리기 등 )\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import pandas as pd\n","import seaborn as sns # 데이터 시각화\n","import matplotlib.pyplot as plt # 그래프 생성\n","tf.__version__"],"metadata":{"id":"AfgUT46T5XJT","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1707315880525,"user_tz":-540,"elapsed":291,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}},"outputId":"10ed6608-c2aa-4c89-c429-2122b16a30f3"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.15.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sux9qO3Pt4o5","executionInfo":{"status":"ok","timestamp":1707315883696,"user_tz":-540,"elapsed":2678,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}},"outputId":"55ce88ef-29e0-4de8-fd89-9272f98a426e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/Colab Notebooks/Project/Computer Vision/src/Datasets/homer_bart_2.zip'\n","zip_object = zipfile.ZipFile(file= path, mode = 'r')\n","zip_object.extractall('./')\n","zip_object.close()"],"metadata":{"id":"K7NX9NVUtnQG","executionInfo":{"status":"ok","timestamp":1707315884778,"user_tz":-540,"elapsed":1083,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# tf를 사용하여 이미지 loading 방법\n","# tf.keras.preprocessing.image.load_img('')"],"metadata":{"id":"0oiAyRzDuPkV","executionInfo":{"status":"ok","timestamp":1707315884779,"user_tz":-540,"elapsed":8,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["### Train and Test set\n","- tensorflow의 ImageDataGenerator 객체를 활용하여 데이터 전처리\n","  - rescale : rescale 값은 이미지의 픽셀 값을 0과 1 사이의 값 정규화 하는데 사용한다. 예를 들어, rescale=1./255는 이미지의 픽셀 값을 0과 1 사이의 값으로 조정하고 rescale=2./255 - 1 는 이미지를 -1과 1 사이의 값으로 조정한다. \"1./255\"에서 1.은 1.0(소수점 표현)이고 /는 나눗셈 연산 255는 나눌 값이다(색상의 값 범위)\n","  - 이미지 증강 설정: 이미지 데이터가 적을때 전처리를 통해 이미지 데이터를 늘릴 수 있다. 다음과 같은 매개변수를 활용하라\n","    - horizontal_flip : 이미지 수평 뒤집기\n","    - rotation_range : 이미지 회전 정도\n","    - zoom_range=0.2 : 이미지 확대 및 축소"],"metadata":{"id":"DkTwAmGKu1Eq"}},{"cell_type":"code","source":["training_generator = ImageDataGenerator(rescale= 1./255, rotation_range=7, horizontal_flip =True, zoom_range=0.2)"],"metadata":{"id":"7ruKuZiSvKd5","executionInfo":{"status":"ok","timestamp":1707315884779,"user_tz":-540,"elapsed":8,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# flow_from_directory : 실제 데이터 로드, shuffle = true 한 이유는 순서가 일정하면 특징이 아닌 순서를 통한 학습을 하기때문\n","train_dataset = training_generator.flow_from_directory('/content/homer_bart_2/training_set', target_size = (64, 64), batch_size =8, class_mode ='categorical', shuffle = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKbYnOs1vfrb","executionInfo":{"status":"ok","timestamp":1707315884779,"user_tz":-540,"elapsed":8,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}},"outputId":"768b58a1-2c14-4f2e-8a6f-832ec0d8c51d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 215 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["train_dataset.classes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_atE7ePfwUN5","executionInfo":{"status":"ok","timestamp":1707315884780,"user_tz":-540,"elapsed":8,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}},"outputId":"2c1049ad-ed45-4e09-917d-043b0f7ca45a"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["train_dataset.class_indices"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pAPgK1JvwacH","executionInfo":{"status":"ok","timestamp":1707315884780,"user_tz":-540,"elapsed":7,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}},"outputId":"f202d956-8959-4393-d040-b46d234c5314"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bart': 0, 'homer': 1}"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["test_generator = ImageDataGenerator(1./255)\n","test_dataset = test_generator.flow_from_directory('/content/homer_bart_2/test_set', target_size = (64, 64), batch_size =1, class_mode = 'categorical', shuffle = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ry0TPeiSweVB","executionInfo":{"status":"ok","timestamp":1707315884780,"user_tz":-540,"elapsed":6,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}},"outputId":"e5bfe0ab-21eb-4958-98a3-5317ebec5787"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 54 images belonging to 2 classes.\n"]}]},{"cell_type":"markdown","source":["# Building and training the neural network"],"metadata":{"id":"-qbAOJvMxBAR"}},{"cell_type":"code","source":["network = Sequential()\n","# conv2D : convolutional층을 생성\n","# 매개변수 : filters = 커널의 개수, kernel_size = 커널의 크기, activation = 특징맵에 적용할 활성화 함수\n","network.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape = (64,64,3)))\n","# conv층에서 생성된 특징맵을 폴링을 이용하여 특징을 확실한 특징 필터링\n","network.add(MaxPool2D(pool_size=(2,2)))\n","\n","network.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n","network.add(MaxPool2D(pool_size=(2,2)))\n","\n","network.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n","network.add(MaxPool2D(pool_size=(2,2)))\n","\n","# 행렬형태의 특징맵을 백터화(일렬로 세움)\n","network.add(Flatten())\n","\n","network.add(Dense(units = 577, activation ='relu'))\n","\n","network.add(Dense(units = 577, activation ='relu'))\n","# softmax는 sigmoid와 달리 이진분류가 아닌 다분류 문제에서 사\n","network.add(Dense(units = 2, activation ='softmax'))\n","\n","# 요약을 활용하여 은닉층의 뉴런 개수를 정하자\n","# (1152+2)/2 =577\n","network.summary()"],"metadata":{"id":"oAW86TvhxVxs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707316000274,"user_tz":-540,"elapsed":291,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}},"outputId":"e24d4b3f-0be3-401e-98a5-340abd07fc43"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_5 (Conv2D)           (None, 62, 62, 32)        896       \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 31, 31, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 29, 29, 32)        9248      \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 14, 14, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 12, 12, 32)        9248      \n","                                                                 \n"," max_pooling2d_5 (MaxPoolin  (None, 6, 6, 32)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_1 (Flatten)         (None, 1152)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 577)               665281    \n","                                                                 \n"," dense_4 (Dense)             (None, 577)               333506    \n","                                                                 \n"," dense_5 (Dense)             (None, 2)                 1156      \n","                                                                 \n","=================================================================\n","Total params: 1019335 (3.89 MB)\n","Trainable params: 1019335 (3.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# loss 함수는 이진분류(binary)이면 binary_crossentropy를 사용, 다분류(categorical)이면 해당 함수를 사용한다.\n","network.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics =['accuracy'])"],"metadata":{"id":"GAj9VLPk9zXS","executionInfo":{"status":"ok","timestamp":1707316198965,"user_tz":-540,"elapsed":2,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["history = network.fit_generator(train_dataset, epochs=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tb65IjNl-cTN","executionInfo":{"status":"ok","timestamp":1707316349412,"user_tz":-540,"elapsed":123919,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}},"outputId":"c1d3fd1a-2a0a-475c-f00d-3423e4b940b4"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-27-5df4b5f3c6a2>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  history = network.fit_generator(train_dataset, epochs=50)\n"]},{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 3s 65ms/step - loss: 0.7208 - accuracy: 0.5767\n","Epoch 2/50\n","27/27 [==============================] - 3s 92ms/step - loss: 0.6680 - accuracy: 0.5814\n","Epoch 3/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.5966 - accuracy: 0.6837\n","Epoch 4/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.5533 - accuracy: 0.7488\n","Epoch 5/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.4979 - accuracy: 0.7488\n","Epoch 6/50\n","27/27 [==============================] - 2s 55ms/step - loss: 0.4441 - accuracy: 0.7674\n","Epoch 7/50\n","27/27 [==============================] - 3s 91ms/step - loss: 0.4092 - accuracy: 0.8093\n","Epoch 8/50\n","27/27 [==============================] - 2s 55ms/step - loss: 0.4403 - accuracy: 0.8186\n","Epoch 9/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.3808 - accuracy: 0.8233\n","Epoch 10/50\n","27/27 [==============================] - 2s 55ms/step - loss: 0.3202 - accuracy: 0.8512\n","Epoch 11/50\n","27/27 [==============================] - 2s 54ms/step - loss: 0.2376 - accuracy: 0.9070\n","Epoch 12/50\n","27/27 [==============================] - 2s 70ms/step - loss: 0.2269 - accuracy: 0.9070\n","Epoch 13/50\n","27/27 [==============================] - 2s 84ms/step - loss: 0.3000 - accuracy: 0.8791\n","Epoch 14/50\n","27/27 [==============================] - 2s 55ms/step - loss: 0.3033 - accuracy: 0.8558\n","Epoch 15/50\n","27/27 [==============================] - 2s 55ms/step - loss: 0.2336 - accuracy: 0.9070\n","Epoch 16/50\n","27/27 [==============================] - 2s 55ms/step - loss: 0.1389 - accuracy: 0.9442\n","Epoch 17/50\n","27/27 [==============================] - 2s 59ms/step - loss: 0.2111 - accuracy: 0.9116\n","Epoch 18/50\n","27/27 [==============================] - 2s 57ms/step - loss: 0.1972 - accuracy: 0.9116\n","Epoch 19/50\n","27/27 [==============================] - 3s 105ms/step - loss: 0.1542 - accuracy: 0.9442\n","Epoch 20/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.0504 - accuracy: 0.9860\n","Epoch 21/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.1662 - accuracy: 0.9535\n","Epoch 22/50\n","27/27 [==============================] - 2s 65ms/step - loss: 0.1743 - accuracy: 0.9256\n","Epoch 23/50\n","27/27 [==============================] - 2s 90ms/step - loss: 0.0892 - accuracy: 0.9674\n","Epoch 24/50\n","27/27 [==============================] - 2s 68ms/step - loss: 0.0868 - accuracy: 0.9674\n","Epoch 25/50\n","27/27 [==============================] - 2s 55ms/step - loss: 0.1143 - accuracy: 0.9581\n","Epoch 26/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.1405 - accuracy: 0.9535\n","Epoch 27/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.0532 - accuracy: 0.9860\n","Epoch 28/50\n","27/27 [==============================] - 2s 58ms/step - loss: 0.0584 - accuracy: 0.9767\n","Epoch 29/50\n","27/27 [==============================] - 2s 87ms/step - loss: 0.1329 - accuracy: 0.9581\n","Epoch 30/50\n","27/27 [==============================] - 2s 57ms/step - loss: 0.1414 - accuracy: 0.9535\n","Epoch 31/50\n","27/27 [==============================] - 2s 54ms/step - loss: 0.0699 - accuracy: 0.9721\n","Epoch 32/50\n","27/27 [==============================] - 2s 58ms/step - loss: 0.0145 - accuracy: 1.0000\n","Epoch 33/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.0862 - accuracy: 0.9767\n","Epoch 34/50\n","27/27 [==============================] - 2s 57ms/step - loss: 0.0555 - accuracy: 0.9814\n","Epoch 35/50\n","27/27 [==============================] - 2s 90ms/step - loss: 0.0743 - accuracy: 0.9628\n","Epoch 36/50\n","27/27 [==============================] - 2s 75ms/step - loss: 0.0738 - accuracy: 0.9814\n","Epoch 37/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.0561 - accuracy: 0.9814\n","Epoch 38/50\n","27/27 [==============================] - 2s 56ms/step - loss: 0.0165 - accuracy: 0.9907\n","Epoch 39/50\n","27/27 [==============================] - 2s 57ms/step - loss: 0.0328 - accuracy: 0.9860\n","Epoch 40/50\n","27/27 [==============================] - 2s 57ms/step - loss: 0.0984 - accuracy: 0.9674\n","Epoch 41/50\n","27/27 [==============================] - 2s 60ms/step - loss: 0.0691 - accuracy: 0.9721\n","Epoch 42/50\n","27/27 [==============================] - 2s 90ms/step - loss: 0.0157 - accuracy: 1.0000\n","Epoch 43/50\n","27/27 [==============================] - 2s 82ms/step - loss: 0.0116 - accuracy: 0.9953\n","Epoch 44/50\n","27/27 [==============================] - 2s 61ms/step - loss: 0.0216 - accuracy: 0.9907\n","Epoch 45/50\n","27/27 [==============================] - 2s 70ms/step - loss: 0.0435 - accuracy: 0.9767\n","Epoch 46/50\n","27/27 [==============================] - 2s 69ms/step - loss: 0.0456 - accuracy: 0.9814\n","Epoch 47/50\n","27/27 [==============================] - 2s 69ms/step - loss: 0.0490 - accuracy: 0.9767\n","Epoch 48/50\n","27/27 [==============================] - 3s 96ms/step - loss: 0.0738 - accuracy: 0.9674\n","Epoch 49/50\n","27/27 [==============================] - 2s 64ms/step - loss: 0.0394 - accuracy: 0.9814\n","Epoch 50/50\n","27/27 [==============================] - 2s 67ms/step - loss: 0.0226 - accuracy: 0.9907\n"]}]}]}